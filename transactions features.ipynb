{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "# print(os.listdir(\"../input\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assume that we save all files in all/ folder in the same directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_train(folder):\n",
    "    df = pd.read_csv('all/train.csv')\n",
    "    df['fdt'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['yr'] = df.fdt.apply(lambda x: x.year)\n",
    "    df['tenure'] = ((datetime.date(2018, 2, 1) - df['fdt'].dt.date).dt.days)/30\n",
    "    return df\n",
    "\n",
    "def read_txns(fname):\n",
    "    df = pd.read_csv(fname)\n",
    "    \n",
    "    # convert to date time\n",
    "    df['purchase_date'] = pd.to_datetime(df.purchase_date)\n",
    "    df['purchase_month'] = df['purchase_date'].dt.month\n",
    "    df['purchase_firstday'] = df['purchase_date'].dt.day==1\n",
    "    # binary \n",
    "    for col in ['authorized_flag', 'category_1']:\n",
    "        df[col] = df[col].map({'Y':1, 'N':0})\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def read_merchant(fname):\n",
    "    # Since category column exist in transaction data already, we filter them out before merge into transaction data \n",
    "    df = pd.read_csv(fname).drop(['category_1', 'category_2'], 1)\n",
    "    return df \n",
    "\n",
    "\n",
    "def evaluate(y, pred):\n",
    "    res = pd.DataFrame({'y':y, 'pred':pred})\n",
    "    res['diff'] = res.y-res.pred\n",
    "    res['ab_diff'] = res['diff'].abs()\n",
    "    res['diff_sq'] = res['diff']**2\n",
    "    res['is_outlier'] = res.y < -33\n",
    "    rmse = np.sqrt(np.mean(res['diff_sq']))\n",
    "    summary = res.groupby('is_outlier').agg({\n",
    "        'ab_diff': ['mean', 'min','max', 'median'],\n",
    "        'y':['count']\n",
    "    })\n",
    "    \n",
    "    return rmse, summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a75c7298e9eee111fa7970c05db1e47692405681"
   },
   "source": [
    "# 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "90499e1748bfe695762f3824548400c2aaef8018",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cards = read_train('')\n",
    "n_txs = read_txns('all/new_merchant_transactions.csv')\n",
    "h_txs = read_txns('all/historical_transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merchant = read_merchant('all/merchants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txs = h_txs.append(n_txs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine merchant with transaction data \n",
    "txs_with_merchant = pd.merge(txs, merchant, how='left', on = 'merchant_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cc49a614ab8906d8c81db39e472c9bc79ae3e768"
   },
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "3359073321839d2d4b2475088a8d4fd044993db0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def agg_tx_features(df, prefix=\"\"):\n",
    "    agg = df.groupby(by='card_id').agg(\n",
    "        {'purchase_amount': ['count','sum','mean','min','max', 'var', 'skew']\n",
    "         ,'merchant_id': ['nunique']\n",
    "         ,'installments': ['sum']\n",
    "         ,'authorized_flag': ['mean']\n",
    "         ,'category_1': ['count']\n",
    "         ,'category_2': ['count']\n",
    "         ,'category_3': ['count']\n",
    "         ,'state_id': ['nunique']\n",
    "         ,'city_id': ['nunique']\n",
    "         ,'purchase_date': ['min', 'max']\n",
    "         ,'purchase_month': ['nunique']\n",
    "         ,'month_lag': ['nunique', 'min', 'max']\n",
    "         ,'purchase_firstday': ['sum', 'mean']  \n",
    "        }).reset_index() \n",
    "    \n",
    "    agg.columns = [\"card_id\"] + [ prefix + '_'.join(tup).rstrip('_') \\\n",
    "                                 for tup in agg.columns.values[1:]]\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "e454d8437191d07626e030ff1c21a63d7acd4877"
   },
   "outputs": [],
   "source": [
    "agg_new = agg_tx_features(txs, \"new_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b014fad1909ecf05e5d2da7747e6e40157e5a321"
   },
   "source": [
    "# Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "79f0869112cd2f55e157e560ec3c496249e3d878",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1 = cards.merge(agg_new, how='left', on='card_id')\n",
    "c1['no_new_tx'] = c1.new_purchase_amount_min.isnull()\n",
    "c1['active_pre_newtx'] = c1.fdt <= n_txs.purchase_date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "31f0c634ae293768af75c6b723ecae5e8930e63b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1 = c1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "5a880c51d37b6d1a7a635e2599b52c980d2d4b3d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat =['yr', \n",
    "       'tenure', \n",
    "       'new_purchase_amount_count',\n",
    "       'new_purchase_amount_sum', \n",
    "       'new_purchase_amount_mean',\n",
    "       'new_purchase_amount_min', \n",
    "       'new_purchase_amount_max',\n",
    "       'new_purchase_amount_var', \n",
    "       'new_purchase_amount_skew',\n",
    "       'new_merchant_id_nunique', \n",
    "       'new_installments_sum',\n",
    "       'new_authorized_flag_mean', \n",
    "       'new_category_1_count',\n",
    "       'new_category_2_count', \n",
    "       'new_category_3_count', \n",
    "       'new_state_id_nunique',\n",
    "       'new_city_id_nunique',\n",
    "       'new_purchase_month_nunique',\n",
    "       'new_month_lag_nunique',\n",
    "       'new_month_lag_min', \n",
    "       'new_month_lag_max', \n",
    "       'new_purchase_firstday_sum',\n",
    "       'new_purchase_firstday_mean', \n",
    "       'no_new_tx', \n",
    "       'active_pre_newtx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with RandomforestRegressor & grid search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "065296a539dff79fad19d4100e14f4c6f3a5a326"
   },
   "outputs": [],
   "source": [
    "# train_df, Y\n",
    "y = c1.target\n",
    "X = c1[feat]\n",
    "\n",
    "# tr, val = train_test_split(train_df, test_size=0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "    \n",
    "# clf.train(tr)\n",
    "clf = RandomForestRegressor()\n",
    "# Grid search params\n",
    "clf_cv = GridSearchCV(clf, {\"colsample_bytree\":[1.0],\"min_child_weight\":[1.0,1.2]\n",
    "                            ,'max_depth': [3,5,10], 'n_estimators': [500,1000, 3000]}, verbose=1)\n",
    "clf_cv.fit(X_train,y_train)\n",
    "clf = RandomForestRegressor(**reg_cv.best_params_) # input best params\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e7c4d59648fbd4a6d827c1093233ac75e615d31a"
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "perf = evaluate(y_test,y_pred)\n",
    "\n",
    "print('rmse:' + str(perf[0]))\n",
    "print(perf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "991ca534da41162d10432fa2aa573ff69eb856e9"
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(clf.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                   columns=['importance']).sort_values('importance',ascending=False)\n",
    "\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with xgb & grid search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse:3.84834011613\n",
      "                y    ab_diff                                 \n",
      "            count       mean        min        max     median\n",
      "is_outlier                                                   \n",
      "False       39919   1.279213   0.000001  16.743164   0.906206\n",
      "True          465  31.735289  27.394949  34.406123  31.868089\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.XGBRegressor()\n",
    "# Grid search params\n",
    "reg_cv = GridSearchCV(gbm, {\"colsample_bytree\":[1.0],\"min_child_weight\":[1.0]\n",
    "                            ,'max_depth': [5,10], 'n_estimators': [1000, 3000]}, verbose=1)\n",
    "reg_cv.fit(X_train,y_train)\n",
    "gbm = xgb.XGBRegressor(**reg_cv.best_params_) # input best params\n",
    "gbm.fit(X_train,y_train)\n",
    "y_pred = gbm.predict(X_test)\n",
    "perf = evaluate(y_test,y_pred)\n",
    "\n",
    "print('rmse:' + str(perf[0]))\n",
    "print(perf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>new_authorized_flag_mean</th>\n",
       "      <td>0.146763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tenure</th>\n",
       "      <td>0.130935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_month_lag_max</th>\n",
       "      <td>0.129496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_month_lag_min</th>\n",
       "      <td>0.120863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_installments_sum</th>\n",
       "      <td>0.080576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_amount_skew</th>\n",
       "      <td>0.063309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_merchant_id_nunique</th>\n",
       "      <td>0.048921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_amount_min</th>\n",
       "      <td>0.047482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_month_lag_nunique</th>\n",
       "      <td>0.035971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_amount_max</th>\n",
       "      <td>0.030216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_amount_mean</th>\n",
       "      <td>0.023022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_firstday_mean</th>\n",
       "      <td>0.021583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_amount_count</th>\n",
       "      <td>0.021583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_amount_var</th>\n",
       "      <td>0.018705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_category_2_count</th>\n",
       "      <td>0.015827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_amount_sum</th>\n",
       "      <td>0.015827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr</th>\n",
       "      <td>0.012950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_month_nunique</th>\n",
       "      <td>0.011511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_firstday_sum</th>\n",
       "      <td>0.008633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_category_3_count</th>\n",
       "      <td>0.007194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_state_id_nunique</th>\n",
       "      <td>0.007194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_city_id_nunique</th>\n",
       "      <td>0.001439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_new_tx</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_category_1_count</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>active_pre_newtx</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            importance\n",
       "new_authorized_flag_mean      0.146763\n",
       "tenure                        0.130935\n",
       "new_month_lag_max             0.129496\n",
       "new_month_lag_min             0.120863\n",
       "new_installments_sum          0.080576\n",
       "new_purchase_amount_skew      0.063309\n",
       "new_merchant_id_nunique       0.048921\n",
       "new_purchase_amount_min       0.047482\n",
       "new_month_lag_nunique         0.035971\n",
       "new_purchase_amount_max       0.030216\n",
       "new_purchase_amount_mean      0.023022\n",
       "new_purchase_firstday_mean    0.021583\n",
       "new_purchase_amount_count     0.021583\n",
       "new_purchase_amount_var       0.018705\n",
       "new_category_2_count          0.015827\n",
       "new_purchase_amount_sum       0.015827\n",
       "yr                            0.012950\n",
       "new_purchase_month_nunique    0.011511\n",
       "new_purchase_firstday_sum     0.008633\n",
       "new_category_3_count          0.007194\n",
       "new_state_id_nunique          0.007194\n",
       "new_city_id_nunique           0.001439\n",
       "no_new_tx                     0.000000\n",
       "new_category_1_count          0.000000\n",
       "active_pre_newtx              0.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(gbm.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                   columns=['importance']).sort_values('importance',ascending=False)\n",
    "\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
